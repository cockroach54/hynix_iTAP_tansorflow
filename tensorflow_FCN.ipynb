{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Demo\n",
    " - 텐서플로 기초 실습\n",
    " > - https://github.com/hunkim/DeepLearningZeroToAll\n",
    "  - https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/\n",
    "  - https://r2rt.com/implementing-batch-normalization-in-tensorflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FI</th>\n",
       "      <th>CD1</th>\n",
       "      <th>CD2</th>\n",
       "      <th>CD</th>\n",
       "      <th>PBCD1</th>\n",
       "      <th>PTCD1</th>\n",
       "      <th>PTHK1</th>\n",
       "      <th>PRTCD1</th>\n",
       "      <th>PRTHK1</th>\n",
       "      <th>HOBCD</th>\n",
       "      <th>...</th>\n",
       "      <th>HOBCD2</th>\n",
       "      <th>MASS</th>\n",
       "      <th>HCBCD</th>\n",
       "      <th>HCBCD1</th>\n",
       "      <th>HCTCD</th>\n",
       "      <th>HCTCD1</th>\n",
       "      <th>HCSBCD</th>\n",
       "      <th>HCSBCD1</th>\n",
       "      <th>HCSTCD</th>\n",
       "      <th>HCSTCD1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fail</td>\n",
       "      <td>34.9425</td>\n",
       "      <td>35.6025</td>\n",
       "      <td>35.6278</td>\n",
       "      <td>30.6582</td>\n",
       "      <td>38.6019</td>\n",
       "      <td>561.1833</td>\n",
       "      <td>42.3682</td>\n",
       "      <td>83.7271</td>\n",
       "      <td>42.6770</td>\n",
       "      <td>...</td>\n",
       "      <td>41.5053</td>\n",
       "      <td>110.3844</td>\n",
       "      <td>30.1095</td>\n",
       "      <td>30.9911</td>\n",
       "      <td>23.4901</td>\n",
       "      <td>24.1715</td>\n",
       "      <td>41.2705</td>\n",
       "      <td>40.3889</td>\n",
       "      <td>48.0099</td>\n",
       "      <td>47.3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fail</td>\n",
       "      <td>35.6638</td>\n",
       "      <td>36.1613</td>\n",
       "      <td>35.8333</td>\n",
       "      <td>31.7862</td>\n",
       "      <td>39.3942</td>\n",
       "      <td>552.6281</td>\n",
       "      <td>43.6462</td>\n",
       "      <td>74.3360</td>\n",
       "      <td>43.4857</td>\n",
       "      <td>...</td>\n",
       "      <td>42.7702</td>\n",
       "      <td>103.7295</td>\n",
       "      <td>30.6316</td>\n",
       "      <td>31.4769</td>\n",
       "      <td>23.0485</td>\n",
       "      <td>23.1552</td>\n",
       "      <td>40.7484</td>\n",
       "      <td>39.9031</td>\n",
       "      <td>48.4515</td>\n",
       "      <td>48.3448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fail</td>\n",
       "      <td>35.2700</td>\n",
       "      <td>36.0663</td>\n",
       "      <td>35.8722</td>\n",
       "      <td>34.0681</td>\n",
       "      <td>38.3055</td>\n",
       "      <td>491.2524</td>\n",
       "      <td>45.9181</td>\n",
       "      <td>76.8525</td>\n",
       "      <td>42.6932</td>\n",
       "      <td>...</td>\n",
       "      <td>42.2894</td>\n",
       "      <td>109.1334</td>\n",
       "      <td>30.4984</td>\n",
       "      <td>31.3457</td>\n",
       "      <td>23.5710</td>\n",
       "      <td>23.3318</td>\n",
       "      <td>40.8816</td>\n",
       "      <td>40.0343</td>\n",
       "      <td>47.8590</td>\n",
       "      <td>48.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fail</td>\n",
       "      <td>35.8425</td>\n",
       "      <td>36.5638</td>\n",
       "      <td>35.9178</td>\n",
       "      <td>32.0579</td>\n",
       "      <td>39.1814</td>\n",
       "      <td>559.7655</td>\n",
       "      <td>43.9179</td>\n",
       "      <td>72.5450</td>\n",
       "      <td>43.5031</td>\n",
       "      <td>...</td>\n",
       "      <td>42.7449</td>\n",
       "      <td>103.4710</td>\n",
       "      <td>30.7320</td>\n",
       "      <td>31.7229</td>\n",
       "      <td>22.8302</td>\n",
       "      <td>22.8603</td>\n",
       "      <td>40.6480</td>\n",
       "      <td>39.6571</td>\n",
       "      <td>48.6698</td>\n",
       "      <td>48.6397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fail</td>\n",
       "      <td>36.0075</td>\n",
       "      <td>36.6700</td>\n",
       "      <td>35.9756</td>\n",
       "      <td>30.0913</td>\n",
       "      <td>38.4956</td>\n",
       "      <td>554.2275</td>\n",
       "      <td>41.5613</td>\n",
       "      <td>74.0503</td>\n",
       "      <td>42.1310</td>\n",
       "      <td>...</td>\n",
       "      <td>41.5634</td>\n",
       "      <td>107.9101</td>\n",
       "      <td>31.2028</td>\n",
       "      <td>31.8770</td>\n",
       "      <td>23.4003</td>\n",
       "      <td>23.2335</td>\n",
       "      <td>40.1772</td>\n",
       "      <td>39.5030</td>\n",
       "      <td>48.1597</td>\n",
       "      <td>48.3265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FI      CD1      CD2       CD    PBCD1    PTCD1     PTHK1   PRTCD1  \\\n",
       "0  fail  34.9425  35.6025  35.6278  30.6582  38.6019  561.1833  42.3682   \n",
       "1  fail  35.6638  36.1613  35.8333  31.7862  39.3942  552.6281  43.6462   \n",
       "2  fail  35.2700  36.0663  35.8722  34.0681  38.3055  491.2524  45.9181   \n",
       "3  fail  35.8425  36.5638  35.9178  32.0579  39.1814  559.7655  43.9179   \n",
       "4  fail  36.0075  36.6700  35.9756  30.0913  38.4956  554.2275  41.5613   \n",
       "\n",
       "    PRTHK1    HOBCD   ...      HOBCD2      MASS    HCBCD   HCBCD1    HCTCD  \\\n",
       "0  83.7271  42.6770   ...     41.5053  110.3844  30.1095  30.9911  23.4901   \n",
       "1  74.3360  43.4857   ...     42.7702  103.7295  30.6316  31.4769  23.0485   \n",
       "2  76.8525  42.6932   ...     42.2894  109.1334  30.4984  31.3457  23.5710   \n",
       "3  72.5450  43.5031   ...     42.7449  103.4710  30.7320  31.7229  22.8302   \n",
       "4  74.0503  42.1310   ...     41.5634  107.9101  31.2028  31.8770  23.4003   \n",
       "\n",
       "    HCTCD1   HCSBCD  HCSBCD1   HCSTCD  HCSTCD1  \n",
       "0  24.1715  41.2705  40.3889  48.0099  47.3285  \n",
       "1  23.1552  40.7484  39.9031  48.4515  48.3448  \n",
       "2  23.3318  40.8816  40.0343  47.8590  48.0982  \n",
       "3  22.8603  40.6480  39.6571  48.6698  48.6397  \n",
       "4  23.2335  40.1772  39.5030  48.1597  48.3265  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BTCC_V1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "## '1.4.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 피처 데이터, 레이블, 미니배치 갯수, random sampling\n",
    "import random\n",
    "def getMiniBatch2(x, y, n):\n",
    "    assert len(x) >= n\n",
    "    if len(x) != len(y):\n",
    "        print('Feature and label num is not equal.')\n",
    "        return\n",
    "    rand_idx = random.sample(list(range(len(x))), n)\n",
    "    x_ = [x[i] for i in rand_idx]\n",
    "    y_ = [y[i] for i in rand_idx]\n",
    "    return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in df['FI']:\n",
    "    y=[]\n",
    "    if i == 'fail': y=[1,0]\n",
    "    else: y=[0,1]\n",
    "    tmp.append(y)\n",
    "df['y'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FI</th>\n",
       "      <th>CD1</th>\n",
       "      <th>CD2</th>\n",
       "      <th>CD</th>\n",
       "      <th>PBCD1</th>\n",
       "      <th>PTCD1</th>\n",
       "      <th>PTHK1</th>\n",
       "      <th>PRTCD1</th>\n",
       "      <th>PRTHK1</th>\n",
       "      <th>HOBCD</th>\n",
       "      <th>...</th>\n",
       "      <th>MASS</th>\n",
       "      <th>HCBCD</th>\n",
       "      <th>HCBCD1</th>\n",
       "      <th>HCTCD</th>\n",
       "      <th>HCTCD1</th>\n",
       "      <th>HCSBCD</th>\n",
       "      <th>HCSBCD1</th>\n",
       "      <th>HCSTCD</th>\n",
       "      <th>HCSTCD1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pass</td>\n",
       "      <td>36.4225</td>\n",
       "      <td>36.4675</td>\n",
       "      <td>37.0511</td>\n",
       "      <td>30.8555</td>\n",
       "      <td>39.0031</td>\n",
       "      <td>551.4198</td>\n",
       "      <td>42.1155</td>\n",
       "      <td>80.0285</td>\n",
       "      <td>43.2955</td>\n",
       "      <td>...</td>\n",
       "      <td>109.6583</td>\n",
       "      <td>30.5914</td>\n",
       "      <td>31.7859</td>\n",
       "      <td>23.3431</td>\n",
       "      <td>22.8038</td>\n",
       "      <td>40.7886</td>\n",
       "      <td>39.5941</td>\n",
       "      <td>48.1569</td>\n",
       "      <td>48.6962</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pass</td>\n",
       "      <td>36.3013</td>\n",
       "      <td>36.9963</td>\n",
       "      <td>36.6156</td>\n",
       "      <td>30.2441</td>\n",
       "      <td>39.5035</td>\n",
       "      <td>555.3825</td>\n",
       "      <td>41.6241</td>\n",
       "      <td>81.3669</td>\n",
       "      <td>42.2831</td>\n",
       "      <td>...</td>\n",
       "      <td>109.6175</td>\n",
       "      <td>30.4597</td>\n",
       "      <td>30.5495</td>\n",
       "      <td>24.2333</td>\n",
       "      <td>25.9690</td>\n",
       "      <td>40.9203</td>\n",
       "      <td>40.8305</td>\n",
       "      <td>47.3767</td>\n",
       "      <td>45.6410</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pass</td>\n",
       "      <td>36.6875</td>\n",
       "      <td>37.3538</td>\n",
       "      <td>36.8367</td>\n",
       "      <td>30.9095</td>\n",
       "      <td>37.9498</td>\n",
       "      <td>557.9170</td>\n",
       "      <td>42.6195</td>\n",
       "      <td>82.5036</td>\n",
       "      <td>42.8688</td>\n",
       "      <td>...</td>\n",
       "      <td>109.9489</td>\n",
       "      <td>30.9015</td>\n",
       "      <td>31.6972</td>\n",
       "      <td>23.0838</td>\n",
       "      <td>22.7425</td>\n",
       "      <td>40.4785</td>\n",
       "      <td>39.6828</td>\n",
       "      <td>48.5762</td>\n",
       "      <td>48.9175</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fail</td>\n",
       "      <td>37.4400</td>\n",
       "      <td>38.5525</td>\n",
       "      <td>37.1333</td>\n",
       "      <td>30.1995</td>\n",
       "      <td>38.9656</td>\n",
       "      <td>560.2790</td>\n",
       "      <td>41.9095</td>\n",
       "      <td>80.1773</td>\n",
       "      <td>42.9534</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0039</td>\n",
       "      <td>30.6956</td>\n",
       "      <td>31.7909</td>\n",
       "      <td>22.9809</td>\n",
       "      <td>22.6807</td>\n",
       "      <td>40.6844</td>\n",
       "      <td>39.5891</td>\n",
       "      <td>48.3191</td>\n",
       "      <td>48.6193</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pass</td>\n",
       "      <td>36.9438</td>\n",
       "      <td>37.5763</td>\n",
       "      <td>36.8022</td>\n",
       "      <td>31.1211</td>\n",
       "      <td>39.2057</td>\n",
       "      <td>560.4731</td>\n",
       "      <td>42.5511</td>\n",
       "      <td>81.9512</td>\n",
       "      <td>42.9143</td>\n",
       "      <td>...</td>\n",
       "      <td>109.2756</td>\n",
       "      <td>30.3826</td>\n",
       "      <td>30.7916</td>\n",
       "      <td>23.9249</td>\n",
       "      <td>24.8209</td>\n",
       "      <td>40.9974</td>\n",
       "      <td>40.5884</td>\n",
       "      <td>47.5751</td>\n",
       "      <td>46.6791</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FI      CD1      CD2       CD    PBCD1    PTCD1     PTHK1   PRTCD1  \\\n",
       "0  pass  36.4225  36.4675  37.0511  30.8555  39.0031  551.4198  42.1155   \n",
       "1  pass  36.3013  36.9963  36.6156  30.2441  39.5035  555.3825  41.6241   \n",
       "2  pass  36.6875  37.3538  36.8367  30.9095  37.9498  557.9170  42.6195   \n",
       "3  fail  37.4400  38.5525  37.1333  30.1995  38.9656  560.2790  41.9095   \n",
       "4  pass  36.9438  37.5763  36.8022  31.1211  39.2057  560.4731  42.5511   \n",
       "\n",
       "    PRTHK1    HOBCD   ...        MASS    HCBCD   HCBCD1    HCTCD   HCTCD1  \\\n",
       "0  80.0285  43.2955   ...    109.6583  30.5914  31.7859  23.3431  22.8038   \n",
       "1  81.3669  42.2831   ...    109.6175  30.4597  30.5495  24.2333  25.9690   \n",
       "2  82.5036  42.8688   ...    109.9489  30.9015  31.6972  23.0838  22.7425   \n",
       "3  80.1773  42.9534   ...    109.0039  30.6956  31.7909  22.9809  22.6807   \n",
       "4  81.9512  42.9143   ...    109.2756  30.3826  30.7916  23.9249  24.8209   \n",
       "\n",
       "    HCSBCD  HCSBCD1   HCSTCD  HCSTCD1       y  \n",
       "0  40.7886  39.5941  48.1569  48.6962  [0, 1]  \n",
       "1  40.9203  40.8305  47.3767  45.6410  [0, 1]  \n",
       "2  40.4785  39.6828  48.5762  48.9175  [0, 1]  \n",
       "3  40.6844  39.5891  48.3191  48.6193  [1, 0]  \n",
       "4  40.9974  40.5884  47.5751  46.6791  [0, 1]  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "split_index = int(len(df)*split_ratio)\n",
    "\n",
    "x_train = (df.iloc[:, 4:21])[:split_index]\n",
    "y_train = df['CD'][:split_index]\n",
    "y_train = [[i] for i in y_train]\n",
    "\n",
    "x_test = (df.iloc[:, 4:21])[split_index:]\n",
    "y_test = df['CD'][split_index:]\n",
    "y_test = [[i] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.as_matrix()\n",
    "y_test = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815 204 815 204\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019, 22)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 300\n",
    "# use mini batch\n",
    "batch_size = 50\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 17]) #[100, 784]\n",
    "Y = tf.placeholder(tf.float32, [None, 1]) #[100, 10]\n",
    "keep_prob = tf.placeholder(tf.float32) # 뉴런을 켤 확률\n",
    "\n",
    "# # weights & bias for nn hidden layers\n",
    "# # 1-hidden layer\n",
    "# W1 = tf.Variable(tf.random_normal([17, 512])) #[784, 256]\n",
    "# b1 = tf.Variable(tf.random_normal([512]))\n",
    "# L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([512, 2]))\n",
    "# b2 = tf.Variable(tf.random_normal([2]))\n",
    "# hypothesis = tf.matmul(L1, W2) + b2\n",
    "\n",
    "W1 = tf.get_variable(name=\"weight_1\", shape=[17, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "W2 = tf.get_variable(name='weight_2', shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "# add Dropout\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "W3 = tf.get_variable(name='weight_3', shape=[256, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "# softmax function\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "\n",
    "# 2-hidden layers\n",
    "# W1 = tf.Variable(tf.random_normal([17, 256]))\n",
    "# b1 = tf.Variable(tf.random_normal([256]))\n",
    "# L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "# b2 = tf.Variable(tf.random_normal([256]))\n",
    "# L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([256, 2]))\n",
    "# b3 = tf.Variable(tf.random_normal([2]))\n",
    "# hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# # 3-hidden layers\n",
    "# W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "# b1 = tf.Variable(tf.random_normal([256]))\n",
    "# L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "# b2 = tf.Variable(tf.random_normal([256]))\n",
    "# L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([256, 256]))\n",
    "# b3 = tf.Variable(tf.random_normal([256]))\n",
    "# L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "# W4 = tf.Variable(tf.random_normal([256, 10]))\n",
    "# b4 = tf.Variable(tf.random_normal([10]))\n",
    "# hypothesis = tf.matmul(L3, W4) + b4\n",
    "\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#     logits=hypothesis, labels=Y))\n",
    "# for regression\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# predicted = tf.argmax(hypothesis, 1)  # [0,0,0,1,0....]--> [3]\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, tf.argmax(Y, 1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total step: 6114\n",
      "step 0: acc_tr 0.704295, acc_tt 0.691176, cost 9.14192e+07\n",
      "step 20: acc_tr 0.704295, acc_tt 0.691176, cost 2.53622e+22\n",
      "step 40: acc_tr 0.704295, acc_tt 0.691176, cost 2.34104e+22\n",
      "step 60: acc_tr 0.704295, acc_tt 0.691176, cost 2.16088e+22\n",
      "step 80: acc_tr 0.704295, acc_tt 0.691176, cost 1.99459e+22\n",
      "step 100: acc_tr 0.704295, acc_tt 0.691176, cost 1.84109e+22\n",
      "step 120: acc_tr 0.704295, acc_tt 0.691176, cost 1.6994e+22\n",
      "step 140: acc_tr 0.704295, acc_tt 0.691176, cost 1.56862e+22\n",
      "step 160: acc_tr 0.704295, acc_tt 0.691176, cost 1.4479e+22\n",
      "step 180: acc_tr 0.704295, acc_tt 0.691176, cost 1.33648e+22\n",
      "step 200: acc_tr 0.704295, acc_tt 0.691176, cost 1.23363e+22\n",
      "step 220: acc_tr 0.704295, acc_tt 0.691176, cost 1.13869e+22\n",
      "step 240: acc_tr 0.704295, acc_tt 0.691176, cost 1.05106e+22\n",
      "step 260: acc_tr 0.704295, acc_tt 0.691176, cost 9.7017e+21\n",
      "step 280: acc_tr 0.704295, acc_tt 0.691176, cost 8.95508e+21\n",
      "step 300: acc_tr 0.704295, acc_tt 0.691176, cost 8.26592e+21\n",
      "step 320: acc_tr 0.704295, acc_tt 0.691176, cost 7.62979e+21\n",
      "step 340: acc_tr 0.704295, acc_tt 0.691176, cost 7.04262e+21\n",
      "step 360: acc_tr 0.704295, acc_tt 0.691176, cost 6.50064e+21\n",
      "step 380: acc_tr 0.704295, acc_tt 0.691176, cost 6.00036e+21\n",
      "step 400: acc_tr 0.704295, acc_tt 0.691176, cost 5.53859e+21\n",
      "step 420: acc_tr 0.704295, acc_tt 0.691176, cost 5.11235e+21\n",
      "step 440: acc_tr 0.704295, acc_tt 0.691176, cost 4.71892e+21\n",
      "step 460: acc_tr 0.704295, acc_tt 0.691176, cost 4.35576e+21\n",
      "step 480: acc_tr 0.704295, acc_tt 0.691176, cost 4.02055e+21\n",
      "step 500: acc_tr 0.704295, acc_tt 0.691176, cost 3.71114e+21\n",
      "step 520: acc_tr 0.704295, acc_tt 0.691176, cost 3.42554e+21\n",
      "step 540: acc_tr 0.704295, acc_tt 0.691176, cost 3.16192e+21\n",
      "step 560: acc_tr 0.704295, acc_tt 0.691176, cost 2.91858e+21\n",
      "step 580: acc_tr 0.704295, acc_tt 0.691176, cost 2.69398e+21\n",
      "step 600: acc_tr 0.704295, acc_tt 0.691176, cost 2.48666e+21\n",
      "step 620: acc_tr 0.704295, acc_tt 0.691176, cost 2.29529e+21\n",
      "step 640: acc_tr 0.704295, acc_tt 0.691176, cost 2.11865e+21\n",
      "step 660: acc_tr 0.704295, acc_tt 0.691176, cost 1.9556e+21\n",
      "step 680: acc_tr 0.704295, acc_tt 0.691176, cost 1.8051e+21\n",
      "step 700: acc_tr 0.704295, acc_tt 0.691176, cost 1.66619e+21\n",
      "step 720: acc_tr 0.704295, acc_tt 0.691176, cost 1.53796e+21\n",
      "step 740: acc_tr 0.704295, acc_tt 0.691176, cost 1.4196e+21\n",
      "step 760: acc_tr 0.704295, acc_tt 0.691176, cost 1.31035e+21\n",
      "step 780: acc_tr 0.704295, acc_tt 0.691176, cost 1.20951e+21\n",
      "step 800: acc_tr 0.704295, acc_tt 0.691176, cost 1.11643e+21\n",
      "step 820: acc_tr 0.704295, acc_tt 0.691176, cost 1.03051e+21\n",
      "step 840: acc_tr 0.704295, acc_tt 0.691176, cost 9.51208e+20\n",
      "step 860: acc_tr 0.704295, acc_tt 0.691176, cost 8.78005e+20\n",
      "step 880: acc_tr 0.704295, acc_tt 0.691176, cost 8.10436e+20\n",
      "step 900: acc_tr 0.704295, acc_tt 0.691176, cost 7.48067e+20\n",
      "step 920: acc_tr 0.704295, acc_tt 0.691176, cost 6.90497e+20\n",
      "step 940: acc_tr 0.704295, acc_tt 0.691176, cost 6.37358e+20\n",
      "step 960: acc_tr 0.704295, acc_tt 0.691176, cost 5.88309e+20\n",
      "step 980: acc_tr 0.704295, acc_tt 0.691176, cost 5.43034e+20\n",
      "step 1000: acc_tr 0.704295, acc_tt 0.691176, cost 5.01243e+20\n",
      "step 1020: acc_tr 0.704295, acc_tt 0.691176, cost 4.62669e+20\n",
      "step 1040: acc_tr 0.704295, acc_tt 0.691176, cost 4.27063e+20\n",
      "step 1060: acc_tr 0.704295, acc_tt 0.691176, cost 3.94197e+20\n",
      "step 1080: acc_tr 0.704295, acc_tt 0.691176, cost 3.63861e+20\n",
      "step 1100: acc_tr 0.704295, acc_tt 0.691176, cost 3.35859e+20\n",
      "step 1120: acc_tr 0.704295, acc_tt 0.691176, cost 3.10012e+20\n",
      "step 1140: acc_tr 0.704295, acc_tt 0.691176, cost 2.86154e+20\n",
      "step 1160: acc_tr 0.704295, acc_tt 0.691176, cost 2.64132e+20\n",
      "step 1180: acc_tr 0.704295, acc_tt 0.691176, cost 2.43805e+20\n",
      "step 1200: acc_tr 0.704295, acc_tt 0.691176, cost 2.25043e+20\n",
      "step 1220: acc_tr 0.704295, acc_tt 0.691176, cost 2.07724e+20\n",
      "step 1240: acc_tr 0.704295, acc_tt 0.691176, cost 1.91738e+20\n",
      "step 1260: acc_tr 0.704295, acc_tt 0.691176, cost 1.76982e+20\n",
      "step 1280: acc_tr 0.704295, acc_tt 0.691176, cost 1.63362e+20\n",
      "step 1300: acc_tr 0.704295, acc_tt 0.691176, cost 1.5079e+20\n",
      "step 1320: acc_tr 0.704295, acc_tt 0.691176, cost 1.39186e+20\n",
      "step 1340: acc_tr 0.704295, acc_tt 0.691176, cost 1.28474e+20\n",
      "step 1360: acc_tr 0.704295, acc_tt 0.691176, cost 1.18587e+20\n",
      "step 1380: acc_tr 0.704295, acc_tt 0.691176, cost 1.09461e+20\n",
      "step 1400: acc_tr 0.704295, acc_tt 0.691176, cost 1.01037e+20\n",
      "step 1420: acc_tr 0.704295, acc_tt 0.691176, cost 9.32618e+19\n",
      "step 1440: acc_tr 0.704295, acc_tt 0.691176, cost 8.60845e+19\n",
      "step 1460: acc_tr 0.704295, acc_tt 0.691176, cost 7.94597e+19\n",
      "step 1480: acc_tr 0.704295, acc_tt 0.691176, cost 7.33447e+19\n",
      "step 1500: acc_tr 0.704295, acc_tt 0.691176, cost 6.77003e+19\n",
      "step 1520: acc_tr 0.704295, acc_tt 0.691176, cost 6.24902e+19\n",
      "step 1540: acc_tr 0.704295, acc_tt 0.691176, cost 5.76811e+19\n",
      "step 1560: acc_tr 0.704295, acc_tt 0.691176, cost 5.32421e+19\n",
      "step 1580: acc_tr 0.704295, acc_tt 0.691176, cost 4.91447e+19\n",
      "step 1600: acc_tr 0.704295, acc_tt 0.691176, cost 4.53627e+19\n",
      "step 1620: acc_tr 0.704295, acc_tt 0.691176, cost 4.18717e+19\n",
      "step 1640: acc_tr 0.704295, acc_tt 0.691176, cost 3.86493e+19\n",
      "step 1660: acc_tr 0.704295, acc_tt 0.691176, cost 3.56749e+19\n",
      "step 1680: acc_tr 0.704295, acc_tt 0.691176, cost 3.29295e+19\n",
      "step 1700: acc_tr 0.704295, acc_tt 0.691176, cost 3.03953e+19\n",
      "step 1720: acc_tr 0.704295, acc_tt 0.691176, cost 2.80562e+19\n",
      "step 1740: acc_tr 0.704295, acc_tt 0.691176, cost 2.5897e+19\n",
      "step 1760: acc_tr 0.704295, acc_tt 0.691176, cost 2.3904e+19\n",
      "step 1780: acc_tr 0.704295, acc_tt 0.691176, cost 2.20644e+19\n",
      "step 1800: acc_tr 0.704295, acc_tt 0.691176, cost 2.03664e+19\n",
      "step 1820: acc_tr 0.704295, acc_tt 0.691176, cost 1.87991e+19\n",
      "step 1840: acc_tr 0.704295, acc_tt 0.691176, cost 1.73523e+19\n",
      "step 1860: acc_tr 0.704295, acc_tt 0.691176, cost 1.60169e+19\n",
      "step 1880: acc_tr 0.704295, acc_tt 0.691176, cost 1.47843e+19\n",
      "step 1900: acc_tr 0.704295, acc_tt 0.691176, cost 1.36466e+19\n",
      "step 1920: acc_tr 0.704295, acc_tt 0.691176, cost 1.25963e+19\n",
      "step 1940: acc_tr 0.704295, acc_tt 0.691176, cost 1.1627e+19\n",
      "step 1960: acc_tr 0.704295, acc_tt 0.691176, cost 1.07322e+19\n",
      "step 1980: acc_tr 0.704295, acc_tt 0.691176, cost 9.90626e+18\n",
      "step 2000: acc_tr 0.704295, acc_tt 0.691176, cost 9.14389e+18\n",
      "step 2020: acc_tr 0.704295, acc_tt 0.691176, cost 8.4402e+18\n",
      "step 2040: acc_tr 0.704295, acc_tt 0.691176, cost 7.79066e+18\n",
      "step 2060: acc_tr 0.704295, acc_tt 0.691176, cost 7.19111e+18\n",
      "step 2080: acc_tr 0.704295, acc_tt 0.691176, cost 6.6377e+18\n",
      "step 2100: acc_tr 0.704295, acc_tt 0.691176, cost 6.12688e+18\n",
      "step 2120: acc_tr 0.704295, acc_tt 0.691176, cost 5.65537e+18\n",
      "step 2140: acc_tr 0.704295, acc_tt 0.691176, cost 5.22015e+18\n",
      "step 2160: acc_tr 0.704295, acc_tt 0.691176, cost 4.81842e+18\n",
      "step 2180: acc_tr 0.704295, acc_tt 0.691176, cost 4.4476e+18\n",
      "step 2200: acc_tr 0.704295, acc_tt 0.691176, cost 4.10533e+18\n",
      "step 2220: acc_tr 0.704295, acc_tt 0.691176, cost 3.78939e+18\n",
      "step 2240: acc_tr 0.704295, acc_tt 0.691176, cost 3.49777e+18\n",
      "step 2260: acc_tr 0.704295, acc_tt 0.691176, cost 3.22859e+18\n",
      "step 2280: acc_tr 0.704295, acc_tt 0.691176, cost 2.98013e+18\n",
      "step 2300: acc_tr 0.704295, acc_tt 0.691176, cost 2.75078e+18\n",
      "step 2320: acc_tr 0.704295, acc_tt 0.691176, cost 2.53909e+18\n",
      "step 2340: acc_tr 0.704295, acc_tt 0.691176, cost 2.34369e+18\n",
      "step 2360: acc_tr 0.704295, acc_tt 0.691176, cost 2.16332e+18\n",
      "step 2380: acc_tr 0.704295, acc_tt 0.691176, cost 1.99684e+18\n",
      "step 2400: acc_tr 0.704295, acc_tt 0.691176, cost 1.84317e+18\n",
      "step 2420: acc_tr 0.704295, acc_tt 0.691176, cost 1.70132e+18\n",
      "step 2440: acc_tr 0.704295, acc_tt 0.691176, cost 1.57039e+18\n",
      "step 2460: acc_tr 0.704295, acc_tt 0.691176, cost 1.44954e+18\n",
      "step 2480: acc_tr 0.704295, acc_tt 0.691176, cost 1.33799e+18\n",
      "step 2500: acc_tr 0.704295, acc_tt 0.691176, cost 1.23502e+18\n",
      "step 2520: acc_tr 0.704295, acc_tt 0.691176, cost 1.13997e+18\n",
      "step 2540: acc_tr 0.704295, acc_tt 0.691176, cost 1.05224e+18\n",
      "step 2560: acc_tr 0.704295, acc_tt 0.691176, cost 9.71267e+17\n",
      "step 2580: acc_tr 0.704295, acc_tt 0.691176, cost 8.9652e+17\n",
      "step 2600: acc_tr 0.704295, acc_tt 0.691176, cost 8.27526e+17\n",
      "step 2620: acc_tr 0.704295, acc_tt 0.691176, cost 7.63842e+17\n",
      "step 2640: acc_tr 0.704295, acc_tt 0.691176, cost 7.05058e+17\n",
      "step 2660: acc_tr 0.704295, acc_tt 0.691176, cost 6.50798e+17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2680: acc_tr 0.704295, acc_tt 0.691176, cost 6.00715e+17\n",
      "step 2700: acc_tr 0.704295, acc_tt 0.691176, cost 5.54485e+17\n",
      "step 2720: acc_tr 0.704295, acc_tt 0.691176, cost 5.11813e+17\n",
      "step 2740: acc_tr 0.704295, acc_tt 0.691176, cost 4.72426e+17\n",
      "step 2760: acc_tr 0.704295, acc_tt 0.691176, cost 4.36069e+17\n",
      "step 2780: acc_tr 0.704295, acc_tt 0.691176, cost 4.0251e+17\n",
      "step 2800: acc_tr 0.704295, acc_tt 0.691176, cost 3.71534e+17\n",
      "step 2820: acc_tr 0.704295, acc_tt 0.691176, cost 3.42941e+17\n",
      "step 2840: acc_tr 0.704295, acc_tt 0.691176, cost 3.16549e+17\n",
      "step 2860: acc_tr 0.704295, acc_tt 0.691176, cost 2.92188e+17\n",
      "step 2880: acc_tr 0.704295, acc_tt 0.691176, cost 2.69702e+17\n",
      "step 2900: acc_tr 0.704295, acc_tt 0.691176, cost 2.48947e+17\n",
      "step 2920: acc_tr 0.704295, acc_tt 0.691176, cost 2.29788e+17\n",
      "step 2940: acc_tr 0.704295, acc_tt 0.691176, cost 2.12104e+17\n",
      "step 2960: acc_tr 0.704295, acc_tt 0.691176, cost 1.95781e+17\n",
      "step 2980: acc_tr 0.704295, acc_tt 0.691176, cost 1.80714e+17\n",
      "step 3000: acc_tr 0.704295, acc_tt 0.691176, cost 1.66807e+17\n",
      "step 3020: acc_tr 0.704295, acc_tt 0.691176, cost 1.5397e+17\n",
      "step 3040: acc_tr 0.704295, acc_tt 0.691176, cost 1.42121e+17\n",
      "step 3060: acc_tr 0.704295, acc_tt 0.691176, cost 1.31184e+17\n",
      "step 3080: acc_tr 0.704295, acc_tt 0.691176, cost 1.21088e+17\n",
      "step 3100: acc_tr 0.704295, acc_tt 0.691176, cost 1.11769e+17\n",
      "step 3120: acc_tr 0.704295, acc_tt 0.691176, cost 1.03168e+17\n",
      "step 3140: acc_tr 0.704295, acc_tt 0.691176, cost 9.52284e+16\n",
      "step 3160: acc_tr 0.704295, acc_tt 0.691176, cost 8.78998e+16\n",
      "step 3180: acc_tr 0.704295, acc_tt 0.691176, cost 8.11352e+16\n",
      "step 3200: acc_tr 0.704295, acc_tt 0.691176, cost 7.48912e+16\n",
      "step 3220: acc_tr 0.704295, acc_tt 0.691176, cost 6.91278e+16\n",
      "step 3240: acc_tr 0.704295, acc_tt 0.691176, cost 6.38079e+16\n",
      "step 3260: acc_tr 0.704295, acc_tt 0.691176, cost 5.88974e+16\n",
      "step 3280: acc_tr 0.704295, acc_tt 0.691176, cost 5.43648e+16\n",
      "step 3300: acc_tr 0.704295, acc_tt 0.691176, cost 5.0181e+16\n",
      "step 3320: acc_tr 0.704295, acc_tt 0.691176, cost 4.63192e+16\n",
      "step 3340: acc_tr 0.704295, acc_tt 0.691176, cost 4.27546e+16\n",
      "step 3360: acc_tr 0.704295, acc_tt 0.691176, cost 3.94643e+16\n",
      "step 3380: acc_tr 0.704295, acc_tt 0.691176, cost 3.64272e+16\n",
      "step 3400: acc_tr 0.704295, acc_tt 0.691176, cost 3.36239e+16\n",
      "step 3420: acc_tr 0.704295, acc_tt 0.691176, cost 3.10362e+16\n",
      "step 3440: acc_tr 0.704295, acc_tt 0.691176, cost 2.86478e+16\n",
      "step 3460: acc_tr 0.704295, acc_tt 0.691176, cost 2.64431e+16\n",
      "step 3480: acc_tr 0.704295, acc_tt 0.691176, cost 2.44081e+16\n",
      "step 3500: acc_tr 0.704295, acc_tt 0.691176, cost 2.25297e+16\n",
      "step 3520: acc_tr 0.704295, acc_tt 0.691176, cost 2.07959e+16\n",
      "step 3540: acc_tr 0.704295, acc_tt 0.691176, cost 1.91955e+16\n",
      "step 3560: acc_tr 0.704295, acc_tt 0.691176, cost 1.77183e+16\n",
      "step 3580: acc_tr 0.704295, acc_tt 0.691176, cost 1.63547e+16\n",
      "step 3600: acc_tr 0.704295, acc_tt 0.691176, cost 1.50961e+16\n",
      "step 3620: acc_tr 0.704295, acc_tt 0.691176, cost 1.39343e+16\n",
      "step 3640: acc_tr 0.704295, acc_tt 0.691176, cost 1.2862e+16\n",
      "step 3660: acc_tr 0.704295, acc_tt 0.691176, cost 1.18721e+16\n",
      "step 3680: acc_tr 0.704295, acc_tt 0.691176, cost 1.09585e+16\n",
      "step 3700: acc_tr 0.704295, acc_tt 0.691176, cost 1.01152e+16\n",
      "step 3720: acc_tr 0.704295, acc_tt 0.691176, cost 9.33671e+15\n",
      "step 3740: acc_tr 0.704295, acc_tt 0.691176, cost 8.61818e+15\n",
      "step 3760: acc_tr 0.704295, acc_tt 0.691176, cost 7.95495e+15\n",
      "step 3780: acc_tr 0.704295, acc_tt 0.691176, cost 7.34276e+15\n",
      "step 3800: acc_tr 0.704295, acc_tt 0.691176, cost 6.77767e+15\n",
      "step 3820: acc_tr 0.704295, acc_tt 0.691176, cost 6.25608e+15\n",
      "step 3840: acc_tr 0.704295, acc_tt 0.691176, cost 5.77463e+15\n",
      "step 3860: acc_tr 0.704295, acc_tt 0.691176, cost 5.33023e+15\n",
      "step 3880: acc_tr 0.704295, acc_tt 0.691176, cost 4.92002e+15\n",
      "step 3900: acc_tr 0.704295, acc_tt 0.691176, cost 4.54139e+15\n",
      "step 3920: acc_tr 0.704295, acc_tt 0.691176, cost 4.1919e+15\n",
      "step 3940: acc_tr 0.704295, acc_tt 0.691176, cost 3.8693e+15\n",
      "step 3960: acc_tr 0.704295, acc_tt 0.691176, cost 3.57153e+15\n",
      "step 3980: acc_tr 0.704295, acc_tt 0.691176, cost 3.29667e+15\n",
      "step 4000: acc_tr 0.704295, acc_tt 0.691176, cost 3.04297e+15\n",
      "step 4020: acc_tr 0.704295, acc_tt 0.691176, cost 2.80879e+15\n",
      "step 4040: acc_tr 0.704295, acc_tt 0.691176, cost 2.59263e+15\n",
      "step 4060: acc_tr 0.704295, acc_tt 0.691176, cost 2.39311e+15\n",
      "step 4080: acc_tr 0.704295, acc_tt 0.691176, cost 2.20894e+15\n",
      "step 4100: acc_tr 0.704295, acc_tt 0.691176, cost 2.03894e+15\n",
      "step 4120: acc_tr 0.704295, acc_tt 0.691176, cost 1.88203e+15\n",
      "step 4140: acc_tr 0.704295, acc_tt 0.691176, cost 1.7372e+15\n",
      "step 4160: acc_tr 0.704295, acc_tt 0.691176, cost 1.60351e+15\n",
      "step 4180: acc_tr 0.704295, acc_tt 0.691176, cost 1.4801e+15\n",
      "step 4200: acc_tr 0.704295, acc_tt 0.691176, cost 1.3662e+15\n",
      "step 4220: acc_tr 0.704295, acc_tt 0.691176, cost 1.26106e+15\n",
      "step 4240: acc_tr 0.704295, acc_tt 0.691176, cost 1.16401e+15\n",
      "step 4260: acc_tr 0.704295, acc_tt 0.691176, cost 1.07443e+15\n",
      "step 4280: acc_tr 0.704295, acc_tt 0.691176, cost 9.91745e+14\n",
      "step 4300: acc_tr 0.704295, acc_tt 0.691176, cost 9.15423e+14\n",
      "step 4320: acc_tr 0.704295, acc_tt 0.691176, cost 8.44974e+14\n",
      "step 4340: acc_tr 0.704295, acc_tt 0.691176, cost 7.79947e+14\n",
      "step 4360: acc_tr 0.704295, acc_tt 0.691176, cost 7.19924e+14\n",
      "step 4380: acc_tr 0.704295, acc_tt 0.691176, cost 6.6452e+14\n",
      "step 4400: acc_tr 0.704295, acc_tt 0.691176, cost 6.1338e+14\n",
      "step 4420: acc_tr 0.704295, acc_tt 0.691176, cost 5.66176e+14\n",
      "step 4440: acc_tr 0.704295, acc_tt 0.691176, cost 5.22605e+14\n",
      "step 4460: acc_tr 0.704295, acc_tt 0.691176, cost 4.82386e+14\n",
      "step 4480: acc_tr 0.704295, acc_tt 0.691176, cost 4.45263e+14\n",
      "step 4500: acc_tr 0.704295, acc_tt 0.691176, cost 4.10997e+14\n",
      "step 4520: acc_tr 0.704295, acc_tt 0.691176, cost 3.79367e+14\n",
      "step 4540: acc_tr 0.704295, acc_tt 0.691176, cost 3.50172e+14\n",
      "step 4560: acc_tr 0.704295, acc_tt 0.691176, cost 3.23224e+14\n",
      "step 4580: acc_tr 0.704295, acc_tt 0.691176, cost 2.98349e+14\n",
      "step 4600: acc_tr 0.704295, acc_tt 0.691176, cost 2.75389e+14\n",
      "step 4620: acc_tr 0.704295, acc_tt 0.691176, cost 2.54196e+14\n",
      "step 4640: acc_tr 0.704295, acc_tt 0.691176, cost 2.34633e+14\n",
      "step 4660: acc_tr 0.704295, acc_tt 0.691176, cost 2.16577e+14\n",
      "step 4680: acc_tr 0.704295, acc_tt 0.691176, cost 1.99909e+14\n",
      "step 4700: acc_tr 0.704295, acc_tt 0.691176, cost 1.84525e+14\n",
      "step 4720: acc_tr 0.704295, acc_tt 0.691176, cost 1.70324e+14\n",
      "step 4740: acc_tr 0.704295, acc_tt 0.691176, cost 1.57217e+14\n",
      "step 4760: acc_tr 0.704295, acc_tt 0.691176, cost 1.45118e+14\n",
      "step 4780: acc_tr 0.704295, acc_tt 0.691176, cost 1.3395e+14\n",
      "step 4800: acc_tr 0.704295, acc_tt 0.691176, cost 1.23641e+14\n",
      "step 4820: acc_tr 0.704295, acc_tt 0.691176, cost 1.14126e+14\n",
      "step 4840: acc_tr 0.704295, acc_tt 0.691176, cost 1.05343e+14\n",
      "step 4860: acc_tr 0.704295, acc_tt 0.691176, cost 9.72363e+13\n",
      "step 4880: acc_tr 0.704295, acc_tt 0.691176, cost 8.97532e+13\n",
      "step 4900: acc_tr 0.704295, acc_tt 0.691176, cost 8.2846e+13\n",
      "step 4920: acc_tr 0.704295, acc_tt 0.691176, cost 7.64704e+13\n",
      "step 4940: acc_tr 0.704295, acc_tt 0.691176, cost 7.05854e+13\n",
      "step 4960: acc_tr 0.704295, acc_tt 0.691176, cost 6.51533e+13\n",
      "step 4980: acc_tr 0.704295, acc_tt 0.691176, cost 6.01392e+13\n",
      "step 5000: acc_tr 0.704295, acc_tt 0.691176, cost 5.55111e+13\n",
      "step 5020: acc_tr 0.704295, acc_tt 0.691176, cost 5.12391e+13\n",
      "step 5040: acc_tr 0.704295, acc_tt 0.691176, cost 4.72958e+13\n",
      "step 5060: acc_tr 0.704295, acc_tt 0.691176, cost 4.36561e+13\n",
      "step 5080: acc_tr 0.704295, acc_tt 0.691176, cost 4.02964e+13\n",
      "step 5100: acc_tr 0.704295, acc_tt 0.691176, cost 3.71953e+13\n",
      "step 5120: acc_tr 0.704295, acc_tt 0.691176, cost 3.43328e+13\n",
      "step 5140: acc_tr 0.704295, acc_tt 0.691176, cost 3.16907e+13\n",
      "step 5160: acc_tr 0.704295, acc_tt 0.691176, cost 2.92518e+13\n",
      "step 5180: acc_tr 0.704295, acc_tt 0.691176, cost 2.70007e+13\n",
      "step 5200: acc_tr 0.704295, acc_tt 0.691176, cost 2.49228e+13\n",
      "step 5220: acc_tr 0.704295, acc_tt 0.691176, cost 2.30048e+13\n",
      "step 5240: acc_tr 0.704295, acc_tt 0.691176, cost 2.12344e+13\n",
      "step 5260: acc_tr 0.704295, acc_tt 0.691176, cost 1.96002e+13\n",
      "step 5280: acc_tr 0.704295, acc_tt 0.691176, cost 1.80919e+13\n",
      "step 5300: acc_tr 0.704295, acc_tt 0.691176, cost 1.66996e+13\n",
      "step 5320: acc_tr 0.704295, acc_tt 0.691176, cost 1.54144e+13\n",
      "step 5340: acc_tr 0.704295, acc_tt 0.691176, cost 1.42281e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5360: acc_tr 0.704295, acc_tt 0.691176, cost 1.31332e+13\n",
      "step 5380: acc_tr 0.704295, acc_tt 0.691176, cost 1.21225e+13\n",
      "step 5400: acc_tr 0.704295, acc_tt 0.691176, cost 1.11896e+13\n",
      "step 5420: acc_tr 0.704295, acc_tt 0.691176, cost 1.03284e+13\n",
      "step 5440: acc_tr 0.704295, acc_tt 0.691176, cost 9.53359e+12\n",
      "step 5460: acc_tr 0.704295, acc_tt 0.691176, cost 8.79991e+12\n",
      "step 5480: acc_tr 0.704295, acc_tt 0.691176, cost 8.12269e+12\n",
      "step 5500: acc_tr 0.704295, acc_tt 0.691176, cost 7.49759e+12\n",
      "step 5520: acc_tr 0.704295, acc_tt 0.691176, cost 6.92059e+12\n",
      "step 5540: acc_tr 0.704295, acc_tt 0.691176, cost 6.388e+12\n",
      "step 5560: acc_tr 0.704295, acc_tt 0.691176, cost 5.89639e+12\n",
      "step 5580: acc_tr 0.704295, acc_tt 0.691176, cost 5.44262e+12\n",
      "step 5600: acc_tr 0.704295, acc_tt 0.691176, cost 5.02377e+12\n",
      "step 5620: acc_tr 0.704295, acc_tt 0.691176, cost 4.63715e+12\n",
      "step 5640: acc_tr 0.704295, acc_tt 0.691176, cost 4.28029e+12\n",
      "step 5660: acc_tr 0.704295, acc_tt 0.691176, cost 3.95089e+12\n",
      "step 5680: acc_tr 0.704295, acc_tt 0.691176, cost 3.64684e+12\n",
      "step 5700: acc_tr 0.704295, acc_tt 0.691176, cost 3.36618e+12\n",
      "step 5720: acc_tr 0.704295, acc_tt 0.691176, cost 3.10713e+12\n",
      "step 5740: acc_tr 0.704295, acc_tt 0.691176, cost 2.86801e+12\n",
      "step 5760: acc_tr 0.704295, acc_tt 0.691176, cost 2.6473e+12\n",
      "step 5780: acc_tr 0.704295, acc_tt 0.691176, cost 2.44357e+12\n",
      "step 5800: acc_tr 0.704295, acc_tt 0.691176, cost 2.25552e+12\n",
      "step 5820: acc_tr 0.704295, acc_tt 0.691176, cost 2.08194e+12\n",
      "step 5840: acc_tr 0.704295, acc_tt 0.691176, cost 1.92172e+12\n",
      "step 5860: acc_tr 0.704295, acc_tt 0.691176, cost 1.77383e+12\n",
      "step 5880: acc_tr 0.704295, acc_tt 0.691176, cost 1.63732e+12\n",
      "step 5900: acc_tr 0.704295, acc_tt 0.691176, cost 1.51131e+12\n",
      "step 5920: acc_tr 0.704295, acc_tt 0.691176, cost 1.39501e+12\n",
      "step 5940: acc_tr 0.704295, acc_tt 0.691176, cost 1.28765e+12\n",
      "step 5960: acc_tr 0.704295, acc_tt 0.691176, cost 1.18856e+12\n",
      "step 5980: acc_tr 0.704295, acc_tt 0.691176, cost 1.09709e+12\n",
      "step 6000: acc_tr 0.704295, acc_tt 0.691176, cost 1.01266e+12\n",
      "step 6020: acc_tr 0.704295, acc_tt 0.691176, cost 9.34728e+11\n",
      "step 6040: acc_tr 0.704295, acc_tt 0.691176, cost 8.62793e+11\n",
      "step 6060: acc_tr 0.704295, acc_tt 0.691176, cost 7.96395e+11\n",
      "step 6080: acc_tr 0.704295, acc_tt 0.691176, cost 7.35106e+11\n",
      "step 6100: acc_tr 0.704295, acc_tt 0.691176, cost 6.78535e+11\n",
      "--------------------------\n",
      "Learning Finished!\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# initialize session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for plotting\n",
    "x_range=[]\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "val_costs=[]\n",
    "\n",
    "total_iter = int(df.shape[0]/batch_size*training_epochs)\n",
    "print('Total step:', total_iter)\n",
    "\n",
    "for i in range(total_iter):\n",
    "#     batch = mnist.train.next_batch(batch_size)\n",
    "#     batch_x, batch_y = getMiniBatch2(x_train.as_matrix(), list(y_train), batch_size)\n",
    "    batch_x = x_train.as_matrix()\n",
    "    batch_y = list(y_train)\n",
    "    optimizer.run(feed_dict={X: batch_x, Y: batch_y, keep_prob:0.5})\n",
    "\n",
    "    if i % 20 == 0:   \n",
    "#         train_accuracy = accuracy.eval(feed_dict={X:batch_x, Y:batch_y, keep_prob:0.5})\n",
    "#         val_accuracy = accuracy.eval(feed_dict={X:x_test, Y:y_test, keep_prob:1})\n",
    "        cost_ = cost.eval(feed_dict={X:x_test, Y:y_test, keep_prob:1})\n",
    "        print('step %d: acc_tr %g, acc_tt %g, cost %g' % (i, train_accuracy, val_accuracy, cost_))\n",
    "\n",
    "        # for plotting\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_costs.append(cost_)\n",
    "        x_range.append(i)\n",
    "\n",
    "print('--------------------------')\n",
    "print('Learning Finished!')\n",
    "\n",
    "# # Test model and check accuracy\n",
    "# print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "#       X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# # Get one and predict\n",
    "# r = random.randint(0, mnist.test.num_examples - 1)\n",
    "# print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "# print(\"Prediction: \", sess.run(\n",
    "#     tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABC8AAAFNCAYAAAAgtUXLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6q3AowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d52aa58358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning result\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(x_range, train_accuracies,'-b', label='Training')\n",
    "plt.plot(x_range, val_accuracies,'-g', label='Validation')\n",
    "plt.legend(loc='lower right', frameon=False)\n",
    "# plt.ylim(ymax = 1.1, ymin = 0.7)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('step')\n",
    "plt.title('FCN: Accuracy')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x_range, val_costs,'-r', label='Validatin_cost')\n",
    "plt.legend(loc='lower right', frameon=False)\n",
    "# plt.ylim(ymax = 1.1, ymin = 0.7)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('step')\n",
    "plt.title('FCN: Validation Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = getMiniBatch2(x_train.as_matrix(), list(y_train), batch_size)\n",
    "print(sum([i[1] for i in batch_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7016683022571149"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "715/1019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019, 22)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n"
     ]
    }
   ],
   "source": [
    "print(sum([i[1] for i in df['y']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "pp = predicted.eval(feed_dict={X:x_test, Y:y_test, keep_prob:1})\n",
    "print(pp)\n",
    "pp2 = predicted.eval(feed_dict={X: batch_x, Y: batch_y, keep_prob:1})\n",
    "print(pp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
